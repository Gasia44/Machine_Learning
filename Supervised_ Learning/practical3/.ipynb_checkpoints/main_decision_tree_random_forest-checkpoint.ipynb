{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dtOmitted\n",
    "import random_forest\n",
    "#import decision_tree\n",
    "import logistic_regression\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n",
    "from logistic_regression import stochastic_gradient_descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'data/SPECTF.dat'\n",
    "data = np.loadtxt(filename, delimiter=',')\n",
    "X = data[:, 1:]\n",
    "Y = np.array([data[:, 0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is the data 2D array, Y is the corresponding responses 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (267, 44)\n",
      "Y shape:  (267, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"Y shape: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59.  52.  70. ...,  74.  64.  67.]\n",
      " [ 72.  62.  69. ...,  71.  56.  58.]\n",
      " [ 71.  62.  70. ...,  41.  51.  46.]\n",
      " ..., \n",
      " [ 75.  73.  72. ...,  75.  67.  71.]\n",
      " [ 59.  62.  72. ...,  76.  70.  70.]\n",
      " [ 64.  66.  68. ...,  64.  57.  54.]]\n",
      "\n",
      " [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(\"\\n\", Y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both X and Y contain integer values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(Y_true, Y_predict):\n",
    "    res = 0\n",
    "    for i in range(len(Y_true)):\n",
    "        if Y_true[i] == Y_predict[i]:\n",
    "            res = res+ 1\n",
    "    return res / len(Y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Random Forest & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials = 20\n",
    "all_accuracies_random_forest = np.zeros(trials)\n",
    "all_std_random_forest = np.zeros(trials)\n",
    "\n",
    "all_accuracies_logistic_regression = np.zeros(trials)\n",
    "all_std_logistic_regression = np.zeros(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = 4  \n",
    "fold_part = int(np.floor(X.shape[0] / folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of Random Forest & Logistic Regression average over 20 trials of 4-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trial in range(trials):\n",
    "    index_array = np.arange(X.shape[0])\n",
    "    np.random.seed(trial*500 +17)\n",
    "    np.random.shuffle(index_array)\n",
    "    accuracy_random_forest = np.zeros(folds)\n",
    "    accuracy_logistic_regression = np.zeros(folds)\n",
    "    \n",
    "    for i in range(folds):\n",
    "        row_idx_train = index_array[np.r_[0: i * fold_part - 0, (i + 1) * fold_part: X.shape[0]]]\n",
    "        Xtrain = X[row_idx_train[:, ], :]\n",
    "        Ytrain = Y[row_idx_train]\n",
    "\n",
    "        row_idx_test = index_array[i * fold_part: (i + 1) * fold_part]\n",
    "        Xtest = X[row_idx_test[:, ], :]\n",
    "        Ytest = Y[row_idx_test]\n",
    "\n",
    "        ####RANDOM FOREST####\n",
    "         # train Random Forest           \n",
    "        classifier = RandomForest(num_trees = 15, max_tree_depth =100, ratio_per_tree=0.50)  ##random forest\n",
    "        classifier.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        # output predictions on the remaining data\n",
    "        Y_pred_random_forest, config = classifier.predict(Xtest)\n",
    "        \n",
    "\n",
    "        #output predictions on the remaining data\n",
    "        Y_pred = classifier.predict(Xtest)\n",
    "        accuracy_random_forest[i] = accuracy_score(Ytest, Y_pred_random_forest)\n",
    "        \n",
    "        ########\n",
    "        \n",
    "        ####Logistic Regression####\n",
    "        ddd = np.column_stack((np.ones(np.array(Xtrain).shape[0]), np.array(Xtrain)))\n",
    "        beta_hat = stochastic_gradient_descent(ddd, (np.array(Ytrain)).ravel(), epsilon=0.0001, l=1, step_size=0.05,max_steps=1000)\n",
    "\n",
    "        dd = np.column_stack((np.ones(np.array(Xtest).shape[0]), np.array(Xtest)))\n",
    "\n",
    "        Y_pred_logistic = []\n",
    "        for j in range(dd.shape[0]):\n",
    "            if dd[j].T.dot(beta_hat) > 0:\n",
    "                Y_pred_logistic.append(1)\n",
    "            else:\n",
    "                Y_pred_logistic.append(0)\n",
    "\n",
    "        accuracy_logistic_regression[i] = accuracy_score(np.array(Ytest.ravel()), np.array(Y_pred_logistic))\n",
    "        ########\n",
    "        \n",
    "    #print(trial, \":  \",\"Random Forest: \",np.mean(accuracy_random_forest),\", Logistic Regression: \", np.mean(accuracy_logistic_regression))\n",
    "        \n",
    "    all_accuracies_random_forest[trial] = np.mean(accuracy_random_forest)\n",
    "    all_std_logistic_regression[trial] = np.mean(accuracy_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanRandomForestAccuracy = np.mean(all_accuracies_random_forest)\n",
    "stddevRandomForestAccuracy = np.std(all_std_logistic_regression)\n",
    "\n",
    "meanLogisticRegressionAccuracy = np.mean(all_std_logistic_regression)\n",
    "stddevLogisticRegressionAccuracy = np.std(all_std_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Random Forest ###\n",
      "Accuracy:  0.746212121212\n",
      "Standard Deviation:  1.11022302463e-16\n"
     ]
    }
   ],
   "source": [
    "print(\"### Random Forest ###\")\n",
    "print(\"Accuracy: \", meanRandomForestAccuracy)\n",
    "print(\"Standard Deviation: \", stddevRandomForestAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest ###\n",
    "\n",
    "Accuracy:  0.746212121212\n",
    "    \n",
    "Standard Deviation:  1.11022302463e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Logistic Regression ###\n",
      "Accuracy:  0.651515151515\n",
      "Standard Deviation:  1.11022302463e-16\n"
     ]
    }
   ],
   "source": [
    "print(\"### Logistic Regression ###\")\n",
    "print(\"Accuracy: \", meanLogisticRegressionAccuracy)\n",
    "print(\"Standard Deviation: \", stddevLogisticRegressionAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression ###\n",
    "Accuracy:  0.651515151515\n",
    "    \n",
    "Standard Deviation:  1.11022302463e-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trials = 100\n",
    "all_accuracies = np.zeros(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = 10  \n",
    "fold_part = int(np.floor(X.shape[0] / folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of decision trees\n",
    "average over 100 trials of 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trial in range(trials):\n",
    "    index_array = np.arange(X.shape[0])\n",
    "    np.random.shuffle(index_array)\n",
    "    accuracy = np.zeros(folds)\n",
    "    stdd = np.zeros(folds)\n",
    "    \n",
    "    for i in range(folds):\n",
    "        row_idx_train = index_array[np.r_[0: i * fold_part - 0, (i + 1) * fold_part: X.shape[0]]]\n",
    "        Xtrain = X[row_idx_train[:, ], :]\n",
    "        Ytrain = Y[row_idx_train]\n",
    "\n",
    "        row_idx_test = index_array[i * fold_part: (i + 1) * fold_part]\n",
    "        Xtest = X[row_idx_test[:, ], :]\n",
    "        Ytest = Y[row_idx_test]\n",
    "\n",
    "        # train the decision tree\n",
    "        classifier = DecisionTree(100)    \n",
    "        classifier.fit(Xtrain, Ytrain)\n",
    "        \n",
    "        # presdict on test set\n",
    "        Y_pred = classifier.predict(Xtest)     \n",
    "        \n",
    "        #output predictions on the remaining data\n",
    "        Y_pred = classifier.predict(Xtest)\n",
    "        accuracy[i] = accuracy_score(Ytest, Y_pred)\n",
    "        \n",
    "    all_accuracies[trial] = np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanDecisionTreeAccuracy = np.mean(all_accuracies)\n",
    "stddevDecisionTreeAccuracy = np.std(all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737653846154\n",
      "0.018781639971\n"
     ]
    }
   ],
   "source": [
    "print(meanDecisionTreeAccuracy)\n",
    "print(stddevDecisionTreeAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "Accuracy: 0.737653846154\n",
    "\n",
    "Standard Deviation: 0.018781639971"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
